<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>openmmdetaction</title>
      <link href="/2022/07/01/openmmlab/"/>
      <url>/2022/07/01/openmmlab/</url>
      
        <content type="html"><![CDATA[<h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><h3 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h3><p>图像分类：</p><ol><li>将图像切分成多块</li><li>用分类算法对每个图像块进行预测</li><li>检测结果=（分类结果，图像位置）</li></ol><p>问题：图像分块过于粗糙，无法检测分块边界上的物体</p><p><strong>改进</strong>：</p><ol><li>使用重叠的窗口，覆盖更多可能出现物体的位置</li><li>用分类算法检测每个图像块</li><li>检测结果=(分类结果，滑窗位置)</li></ol><p>问题：滑窗边界与物体精确边界有偏差</p><p><strong>改进</strong>：分类的同时预测物体的精确位置 –<strong>边界框回归</strong></p><p><strong>问题</strong>：不同物体大小不同，长宽比不同</p><p><strong>解决方案：</strong></p><ol><li><p>使用大小不同，长宽比不同的滑窗（yolo里面是9种）</p><p><img src="/2022/07/01/openmmlab/image-20220701140554357.png"></p></li><li><p>将图像缩放到不同大小，构建图像金字塔，相同大小的窗口在不同尺寸的图像上可以检测不同尺寸的物体</p></li></ol><p><img src="/2022/07/01/openmmlab/image-20220701140331584.png"></p><p>滑窗 = 空间上的密集预测</p><p>考虑800×600的图像，使用80×60的窗，步长10像素滑动</p><p>需要在4800个窗上进行分类预测</p><p>×每个位置5个尺度的窗</p><p>×每个尺度3个长宽比</p><p>≈检测一张图像需要完成数万次图像分类预测 （<font color="red">难以实现实时检测</font>）</p><p><strong>分析：</strong>大量窗口都落在不包含物体的边界区域。可以先通过简单快速的方法找出可能含物体的区域。</p><p><strong>Selective Search算法：</strong></p><p>使用贪心算法，将空间相邻且特征相似的图像块逐步合并到一起，形成可能包含物体的区域，<strong>称为提议区域或提议框</strong>。</p><p><img src="/2022/07/01/openmmlab/image-20220701150042983.png"></p>]]></content>
      
      
      <categories>
          
          <category> openmmlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolo</title>
      <link href="/2022/06/24/yolo/"/>
      <url>/2022/06/24/yolo/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>yolov3说明</title>
      <link href="/2022/06/23/yolov3-shuo-ming/"/>
      <url>/2022/06/23/yolov3-shuo-ming/</url>
      
        <content type="html"><![CDATA[<ul><li><p>yolo是根据中心点，w和h  （速度快，互不影响）</p></li><li><p>传统目标检测：左下角和右下角的坐标</p></li></ul><p>yolo将物体分为了9种：大中小—正方形 长矩形 竖矩形</p><p>首先把图片等分，然后根据锚点画框，最后通过IOU来判断框。</p><p>偏移量：通过中心点的坐标去数格子，坐标除以格子的宽度可以得到格子的位置 再分离整数部分和小数部分，小数部分就是偏移量。（求pw,ph,分类）【对神经网络的输出取指数，最后取对数】</p><p>1*1卷积的目的是降通道，例如（32，32，10）通过（1，1，10）生成（32，32，1）的特征图</p><p>3*3卷积的目的是像素融合并进行降通道</p><p>下采样原理:图像尺寸为M<em>N。对其进行s倍下采样，即得到（M/s）</em>(N/s)尺寸的分辨率图像，s需为M和N的公约数，对于矩阵形式图像的含义即为将原始图像s*s窗口内的图像编程为一个像素，这个像素点的值就是窗口内所有像素的均值。在YOLOv3的网络结构中并未采用最大值池化或平均值池化方法进行降采样，而是采用步长为2的卷积来进行降采样。</p><p>上采样原理:图像放大几乎都是采用内插值方法，即在原有图像的基础上在各个像素之间采用合适的插值算法插入新的元素。</p><p>在YOLOv3的网络结构中共图像的像素进行了5次下采样，每次采样步长为2，所以输入图像的大小需要为32的倍数。</p><p>concat层：张量拼接 将darknet中间层和后面的某一层的上采样进行拼接（特征有前后关系，深度不同的情况下）</p><p><img src="/2022/06/23/yolov3-shuo-ming/image-20220609191045044.png"></p><p><span class="github-emoji"><span>😂</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></p>]]></content>
      
      
      <categories>
          
          <category> yolo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
